{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a5232e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, SequentialSampler, TensorDataset\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e6ea3c",
   "metadata": {},
   "source": [
    "# 영/한 댓글 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a59dcf",
   "metadata": {},
   "source": [
    "## - filepath 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1caced21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[course_id: string, comment: string, language: string]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lower, regexp_replace, udf\n",
    "from pyspark.sql.types import BooleanType, StringType\n",
    "from langid.langid import LanguageIdentifier, model\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"UdemyCommentsAnalysis\").getOrCreate()\n",
    "#df = spark.read.format(\"csv\") \\\n",
    "#                       .option(\"header\", \"true\") \\\n",
    "#                       .option(\"inferSchema\", \"true\") \\\n",
    "#                       .option(\"encoding\",\"UTF-8\") \\\n",
    "#                       .load(\"merged_comments_30rows.csv\")\n",
    "\n",
    "file_path = \"file:///home/hyunjin6/Documents/workspace/merged_comments.csv\"\n",
    "\n",
    "reviews_df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "reviews_df = reviews_df.withColumn('comment', lower(col('comment')))\n",
    "reviews_df = reviews_df.withColumn('comment', regexp_replace(col('comment'), '[^\\w\\s]', ''))\n",
    "\n",
    "identifier = LanguageIdentifier.from_modelstring(model, norm_probs=True)\n",
    "\n",
    "def detect_language_langid(comment):\n",
    "    try:\n",
    "        lang, _ = identifier.classify(comment)\n",
    "        return lang\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "detect_language_udf = udf(detect_language_langid, StringType())\n",
    "\n",
    "reviews_df = reviews_df.withColumn(\"language\", detect_language_udf(col(\"comment\")))\n",
    "\n",
    "filtered_comments_df = reviews_df.filter((col(\"language\") == \"en\") | (col(\"language\") == \"ko\"))\n",
    "\n",
    "\n",
    "print(filtered_comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa12d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------+\n",
      "|course_id|             comment|language|\n",
      "+---------+--------------------+--------+\n",
      "|  3173036|i think a beginne...|      en|\n",
      "|  4913148|aviva is such a n...|      en|\n",
      "|  3175814|this course is th...|      en|\n",
      "|  3174896|i found this cour...|      en|\n",
      "|  4693438|nothing informati...|      en|\n",
      "|  4693272|multiple spelling...|      en|\n",
      "|  3168632|very unique way o...|      en|\n",
      "|  3188362|                    |      en|\n",
      "|  4164550|good course  info...|      en|\n",
      "|  4164836|thanks kate great...|      en|\n",
      "|  4693624|halfway thru very...|      en|\n",
      "|  4695130|its a pretty good...|      en|\n",
      "|  4694990|it was very nice ...|      en|\n",
      "|  4165910|it is the best co...|      en|\n",
      "|  4695172|i have watched tw...|      en|\n",
      "|  4694460|all about radio a...|      en|\n",
      "|  4163248|should have provi...|      en|\n",
      "|  3175482|amazing course an...|      en|\n",
      "|  3157018|                    |      en|\n",
      "|  3152462|excellent present...|      en|\n",
      "+---------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filtered_comments_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14ed91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_comments_df = filtered_comments_df.filter(col(\"language\") == \"ko\")\n",
    "korean_comments_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a944d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_comments_count = korean_comments_df.count()\n",
    "print(f\"Number of comments in Korean: {korean_comments_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e20881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_comments_df = filtered_comments_df.limit(5000)\n",
    "filtered_comments_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a11987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_comments_df.repartition(1).write.csv(\"file:///home/hyunjin6/Documents/workspace/comments_enko.csv\", header=True, mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62dc4313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: 안녕하세요 -> Language: ko\n",
      "Comment: Hello -> Language: en\n",
      "Comment: Bonjour -> Language: en\n",
      "Comment: こんにちは -> Language: ja\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "test_comments = [\"안녕하세요\", \"Hello\", \"Bonjour\", \"こんにちは\"]\n",
    "for comment in test_comments:\n",
    "    print(f\"Comment: {comment} -> Language: {detect_language_langid(comment)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70f58e4",
   "metadata": {},
   "source": [
    "# 영어 댓글 긍/부정 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2dafbda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def preprocess_data(comments, tokenizer, max_len):\n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "        comments,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return inputs\n",
    "\n",
    "def classify_sentiment(comments):\n",
    "    model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "    \n",
    "    max_len = 64\n",
    "    inputs = preprocess_data(comments, tokenizer, max_len)\n",
    "\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    dataset = TensorDataset(input_ids, attention_mask)\n",
    "    dataloader = DataLoader(dataset, sampler=SequentialSampler(dataset), batch_size=32)\n",
    "\n",
    "    model.eval()\n",
    "    sentiments = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch = tuple(t.to('cpu') for t in batch)\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1]}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs[0]\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            sentiments.append(probs.cpu().numpy())\n",
    "\n",
    "    sentiments = np.concatenate(sentiments, axis=0)\n",
    "    sentiments = np.argmax(sentiments, axis=1)\n",
    "\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b94934d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/hyunjin6/Documents/venv/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2383: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "comments = english_comments_df.select('comment').rdd.flatMap(lambda x: x).collect()\n",
    "sentiments = classify_sentiment(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee32e800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "english_comments_pd = english_comments_df.toPandas()\n",
    "english_comments_pd['sentiment'] = sentiments\n",
    "english_comments_pd['sentiment_label'] = english_comments_pd['sentiment'].apply(lambda x: 'positive' if x > 2 else 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49ff6a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_en_comments_pd = english_comments_pd[english_comments_pd['sentiment_label'] == 'positive']\n",
    "negative_en_comments_pd = english_comments_pd[english_comments_pd['sentiment_label'] == 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7673c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_en_comments_pd = pd.concat([positive_en_comments_pd, negative_en_comments_pd])\n",
    "\n",
    "#print(merged_en_comments_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_en_comments_pd.to_csv('en_comments_p_n.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "989ddafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   course_id                                            comment language  \\\n",
      "1    4913148  aviva is such a natural teacher and healerheal...       en   \n",
      "2    3175814  this course is the best on udemy  this breakda...       en   \n",
      "3    3174896  i found this course very helpful it was full o...       en   \n",
      "6    3168632  very unique way of teaching simple but powerfu...       en   \n",
      "7    3188362                                                          en   \n",
      "8    4164550  good course  information is well organized cle...       en   \n",
      "9    4164836  thanks kate great course and valuable informat...       en   \n",
      "10   4693624            halfway thru very good course thank you       en   \n",
      "11   4695130  its a pretty good course ive managed to create...       en   \n",
      "12   4694990  it was very nice explanation many thanks for s...       en   \n",
      "13   4165910  it is the best course i have seen on these top...       en   \n",
      "14   4695172               i have watched two lesson it is good       en   \n",
      "17   3175482  amazing course and great information thank u k...       en   \n",
      "18   3157018                                                          en   \n",
      "19   3152462  excellent presentation with practical and spec...       en   \n",
      "20   4169606  i would love to thank you so much for your har...       en   \n",
      "21   3156192                                                          en   \n",
      "22   4692490                                          excelente       en   \n",
      "23   4692270  this is beyond all expectations easy to learn ...       en   \n",
      "24   3165688                           nice full of information       en   \n",
      "0    3173036       i think a beginner needs more than you think       en   \n",
      "4    4693438                          nothing information there       en   \n",
      "5    4693272  multiple spelling mistakes and one or more que...       en   \n",
      "15   4694460          all about radio airplay not the streaming       en   \n",
      "16   4163248  should have provided workbooks or links to the...       en   \n",
      "\n",
      "    sentiment sentiment_label  \n",
      "1           4        positive  \n",
      "2           4        positive  \n",
      "3           4        positive  \n",
      "6           4        positive  \n",
      "7           3        positive  \n",
      "8           3        positive  \n",
      "9           4        positive  \n",
      "10          4        positive  \n",
      "11          3        positive  \n",
      "12          4        positive  \n",
      "13          4        positive  \n",
      "14          3        positive  \n",
      "17          4        positive  \n",
      "18          3        positive  \n",
      "19          4        positive  \n",
      "20          4        positive  \n",
      "21          3        positive  \n",
      "22          4        positive  \n",
      "23          4        positive  \n",
      "24          3        positive  \n",
      "0           2        negative  \n",
      "4           0        negative  \n",
      "5           0        negative  \n",
      "15          0        negative  \n",
      "16          2        negative  \n"
     ]
    }
   ],
   "source": [
    "print(merged_en_comments_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb571e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
